{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dijkstra algorithm for sparse graphs\n",
    "\n",
    "Implement the refined Dijkstra algorithm from the paper [An improved Dijkstraâ€™s shortest path algorithm for sparse network](https://www.sciencedirect.com/science/article/abs/pii/S0096300306008563). Check if its performance is faster than the simple heapq Dijkstra "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The core change is in the handling of the list of $l(\\cdot)$'s of tentative distances. Instead of using a heap data structure and the likes: for the extracting of the minimum distance, insertion/updates of tentative distances, and maintaining the sorted order of the list, we make use of a different method for the insertion of the new distance $l(\\cdot)$ and where to insert it into the list (Steps $2.1.1$ and $2.1.2$)\n",
    "\n",
    "- $2.1.1)$ Let $high_i^v$ be the position of entry $l(v)$ at the list $l$\n",
    "- $2.1.2)$ Sort list $l$ by reinserting the entry $l(v)$ in a proper position between position $low_i$ and $high_i^v$ of list $l$\n",
    "\n",
    "So for each iteration it just takes the next position from the list as the minimum: since the sorting of the list is handled by the previous two process of properly reinserting the entry $l(v)$ and upholding the order of the list\n",
    "\n",
    "Conceptually, $2.1.2$ is just a binary search between the length of $low_i$ and $high_i^v$ since the sublist across this length is nondecreasing. Traditionally binary search divides the length to find the midpoint, but here we incorporate a step size vector which gives the midpoint for each length (avoiding division) in the binary search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heap implementation\n",
    "import heapq\n",
    "\n",
    "\n",
    "def dijkstra_heap(G, source, target):\n",
    "    visited = set()\n",
    "    queue = [(0, source, None)]  # (tentative cost, vertex, parent)\n",
    "    parents = {}\n",
    "    \n",
    "    while queue:\n",
    "        vertex_cost, vertex, parent = heapq.heappop(queue)  # Get lowest cost vertex from the queue\n",
    "\n",
    "        if vertex in visited:\n",
    "            continue\n",
    "\n",
    "        visited.add(vertex) # Consider vertex as visited\n",
    "        parents[vertex] = parent\n",
    "        \n",
    "        # End algorithm when vertex visited is the goal node\n",
    "        if vertex == target:\n",
    "            break\n",
    "\n",
    "        # Relax neighbor vertices of vertex\n",
    "        for _, neighbor, edge_length in G.out_edges(vertex, data=\"length\"):\n",
    "            if neighbor in visited:\n",
    "                continue\n",
    "\n",
    "            # No need to check if new cost is an improvement, just add it to the queue; other costs will be disregarded later on\n",
    "            neighbor_cost = vertex_cost + edge_length \n",
    "            heapq.heappush(queue, (neighbor_cost, neighbor, vertex))\n",
    "\n",
    "    return parents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The structure of the code, I think, will still closely follow the heap implemenetation previously. But the popping and inserting of vertices will be totally different (and also the data structures used). I think it would be beneficial to also try to retain the efficiency quirks of the heap implementation: not adding all the vertices from the start; multiple costs for same vertices existing in the queue. But not sure if they would apply\n",
    "\n",
    "One issue I'm seeing is that we'd have to find a way of getting the position of the vertex in the list. Suppose that we successfully implement the data structure replacing the heap process; but the introduction of $O(n)$ searches might make the performance all the same if not worse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sparse implementation\n",
    "\n",
    "def dijkstra_sparse(G, source, target):\n",
    "    visited = set()\n",
    "    queue = [(0, source, None)]  # (tentative cost, vertex, parent)\n",
    "    parents = {}\n",
    "    \n",
    "    low = 0\n",
    "    while queue:\n",
    "        vertex_cost, vertex, parent = queue[low]\n",
    "\n",
    "        if vertex not in visited:\n",
    "            visited.add(vertex) # Consider vertex as visited\n",
    "            parents[vertex] = parent\n",
    "\n",
    "            # Relax neighbor vertices of vertex\n",
    "            for _, neighbor, edge_length in G.out_edges(vertex, data=\"length\"):\n",
    "                if neighbor not in visited:\n",
    "                    neighbor_cost = vertex_cost + edge_length \n",
    "                    queue.append((neighbor_cost, neighbor, vertex))\n",
    "\n",
    "        low += 1\n",
    "\n",
    "    return parents"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
